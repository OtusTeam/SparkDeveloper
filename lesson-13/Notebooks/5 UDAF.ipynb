{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9157853e-0a6e-4cbe-bd75-dc7140b2a070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.5`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c06e9d-a8ce-4b5b-a221-1197d6d1aa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c28eed4-44ce-4ee0-9cf0-4a67c80b94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/03/13 16:38:32 INFO SparkContext: Running Spark version 3.5.5\n",
      "25/03/13 16:38:32 INFO SparkContext: OS info Mac OS X, 15.3.2, aarch64\n",
      "25/03/13 16:38:32 INFO SparkContext: Java version 11.0.26\n",
      "25/03/13 16:38:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting Spark log level to \"WARN\".\n",
      "25/03/13 16:38:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/13 16:38:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@166ae44a\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"UDAF\")\n",
    "                .config(\"spark.log.level\", \"WARN\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907b685",
   "metadata": {},
   "source": [
    "## Простой пример: Среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecc6411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|   name|depId|salary|\n",
      "+-------+-----+------+\n",
      "|Michael|    1|  3000|\n",
      "|Michael|    2|  6000|\n",
      "|   Andy|    1|  4500|\n",
      "|   Andy|    2|  2500|\n",
      "| Justin|    3|  3500|\n",
      "|  Berta|    3|  4000|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [name: string, depId: int ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data1 = Seq(\n",
    "                (\"Michael\", 1, 3000),\n",
    "                (\"Michael\", 2, 6000),\n",
    "                (\"Andy\", 1, 4500),\n",
    "                (\"Andy\", 2, 2500),\n",
    "                (\"Justin\", 3, 3500),\n",
    "                (\"Berta\", 3, 4000))\n",
    "            .toDF(\"name\", \"depId\", \"salary\")\n",
    "\n",
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45addd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mAverage\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mMyAverage\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(this)\n",
    "\n",
    "case class Average(var sum: Long, var count: Long)\n",
    "\n",
    "class MyAverage extends Aggregator[Long, Average, Double] {\n",
    "  // Начальное значение. Должно соответствовать свойству: любое b + zero = b\n",
    "  def zero: Average = Average(0L, 0L)\n",
    "  // Объединение двух значений в новое значение.\n",
    "  // Для повышения производительности функция может изменять `buffer` и \n",
    "  // возвращать его вместо создания нового объекта.\n",
    "  def reduce(buffer: Average, data: Long): Average = {\n",
    "    buffer.sum += data\n",
    "    buffer.count += 1\n",
    "    buffer\n",
    "  }\n",
    "  // Объединение двух промежуточных значения\n",
    "  def merge(b1: Average, b2: Average): Average = {\n",
    "    b1.sum += b2.sum\n",
    "    b1.count += b2.count\n",
    "    b1\n",
    "  }\n",
    "  // Преобразование выходных данных\n",
    "  def finish(reduction: Average): Double = reduction.sum.toDouble / reduction.count\n",
    "  // Кодировщик для типа промежуточного значения\n",
    "  def bufferEncoder: Encoder[Average] = Encoders.product\n",
    "  // Кодировщик для типа выходного значения\n",
    "  def outputEncoder: Encoder[Double] = Encoders.scalaDouble\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c7c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmyAverageUDAF\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedAggregator\u001b[39m(\n",
       "  ammonite.$sess.cmd5$Helper$MyAverage@5b22064b,\n",
       "  \u001b[33mExpressionEncoder\u001b[39m(\n",
       "    \u001b[33mBoundReference\u001b[39m(\u001b[32m0\u001b[39m, LongType, \u001b[32mfalse\u001b[39m),\n",
       "    \u001b[33mAssertNotNull\u001b[39m(\n",
       "      \u001b[33mUpCast\u001b[39m(\n",
       "        \u001b[33mGetColumnByOrdinal\u001b[39m(\u001b[32m0\u001b[39m, LongType),\n",
       "        LongType,\n",
       "        \u001b[33mList\u001b[39m(\u001b[32m\"- root class: \\\"long\\\"\"\u001b[39m)\n",
       "      ),\n",
       "      \u001b[33mList\u001b[39m(\u001b[32m\"- root class: \\\"long\\\"\"\u001b[39m)\n",
       "    ),\n",
       "    Long\n",
       "  ),\n",
       "  \u001b[32mNone\u001b[39m,\n",
       "  \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val myAverageUDAF = udaf(new MyAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8718ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|depId|average_salary|\n",
      "+-----+--------------+\n",
      "|    1|        3750.0|\n",
      "|    2|        4250.0|\n",
      "|    3|        3750.0|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1\n",
    "    .groupBy(\"depId\")\n",
    "    .agg(myAverageUDAF($\"salary\").as(\"average_salary\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff419ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|   name|average_salary|\n",
      "+-------+--------------+\n",
      "|Michael|        4500.0|\n",
      "|   Andy|        3500.0|\n",
      "| Justin|        3500.0|\n",
      "|  Berta|        4000.0|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1\n",
    "    .groupBy($\"name\")\n",
    "    .agg(myAverageUDAF($\"salary\").as(\"average_salary\"))\n",
    "    .show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeaaf7a",
   "metadata": {},
   "source": [
    "## Продвинутый пример: сумма с ограничением"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0114f8",
   "metadata": {},
   "source": [
    "Каждый клиент получает один балл за каждую заказанную единицу товара, но неболее трёх баллов в одном заказе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c579a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 4 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 1, 300, 1551903533),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 2, 120, 1551903567),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"CA\" ,4, 75, 1551903599),\n",
    "    (\"Holden\", \"Karau\", \"CA\" , 6, 37, 1551904299),\n",
    "    (\"Ginni\", \"Rometty\", \"NY\", 7, 91, 1551916792),\n",
    "    (\"Holden\", \"Karau\", \"CA\", 4, 153, 1552876129)\n",
    ").toDF(\"firstName\", \"lastName\", \"state\", \"quantity\", \"revenue\", \"timestamp\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e7a296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mBuffer\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mPointAttribution\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(this)\n",
    "\n",
    "case class Buffer(var value: Int) \n",
    "\n",
    "class PointAttribution extends Aggregator[Int, Buffer, Int] {\n",
    "  val MAX_POINT_PER_ORDER = 3\n",
    "  // Начальное значение. Должно соответствовать свойству: любое b + zero = b\n",
    "  def zero: Buffer = Buffer(0)\n",
    "  // Объединение двух значений в новое значение.\n",
    "  // Для повышения производительности функция может изменять `buffer` и \n",
    "  // возвращать его вместо создания нового объекта.\n",
    "  def reduce(buffer: Buffer, data: Int): Buffer = {\n",
    "    val outputValue = if (data < MAX_POINT_PER_ORDER) data else MAX_POINT_PER_ORDER\n",
    "    buffer.value += outputValue\n",
    "    buffer\n",
    "  }\n",
    "  // Объединение двух промежуточных значения\n",
    "  def merge(b1: Buffer, b2: Buffer): Buffer = {\n",
    "    b1.value += b2.value\n",
    "    b1\n",
    "  }\n",
    "  // Преобразование выходных данных\n",
    "  def finish(reduction: Buffer): Int = reduction.value\n",
    "  // Кодировщик для типа промежуточного значения\n",
    "  def bufferEncoder: Encoder[Buffer] = Encoders.product\n",
    "  // Кодировщик для типа выходного значения\n",
    "  def outputEncoder: Encoder[Int] = Encoders.scalaInt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b44e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpointAttribution\u001b[39m: \u001b[32mPointAttribution\u001b[39m = ammonite.$sess.cmd10$Helper$PointAttribution@668d50ee\n",
       "\u001b[36mpointAttributionUDAF\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedAggregator\u001b[39m(\n",
       "  ammonite.$sess.cmd10$Helper$PointAttribution@668d50ee,\n",
       "  \u001b[33mExpressionEncoder\u001b[39m(\n",
       "    \u001b[33mBoundReference\u001b[39m(\u001b[32m0\u001b[39m, IntegerType, \u001b[32mfalse\u001b[39m),\n",
       "    \u001b[33mAssertNotNull\u001b[39m(\n",
       "      \u001b[33mUpCast\u001b[39m(\n",
       "        \u001b[33mGetColumnByOrdinal\u001b[39m(\u001b[32m0\u001b[39m, IntegerType),\n",
       "        IntegerType,\n",
       "        \u001b[33mList\u001b[39m(\u001b[32m\"- root class: \\\"int\\\"\"\u001b[39m)\n",
       "      ),\n",
       "      \u001b[33mList\u001b[39m(\u001b[32m\"- root class: \\\"int\\\"\"\u001b[39m)\n",
       "    ),\n",
       "    Int\n",
       "  ),\n",
       "  \u001b[32mNone\u001b[39m,\n",
       "  \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pointAttribution = new PointAttribution\n",
    "val pointAttributionUDAF = udaf(pointAttribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+-------------+-----+\n",
      "|   firstName|lastName|state|sum(quantity)|point|\n",
      "+------------+--------+-----+-------------+-----+\n",
      "|Jean-Georges|  Perrin|   NC|            3|    3|\n",
      "|Jean-Georges|  Perrin|   CA|            4|    3|\n",
      "|      Holden|   Karau|   CA|           10|    6|\n",
      "|       Ginni| Rometty|   NY|            7|    3|\n",
      "+------------+--------+-----+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mt1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m22905627996458L\u001b[39m\n",
       "\u001b[36mduration1\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m2.065082583\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val t1 = System.nanoTime\n",
    "\n",
    "data\n",
    "  .groupBy($\"firstName\", $\"lastName\", $\"state\")\n",
    "  .agg(sum(\"quantity\"), pointAttributionUDAF($\"quantity\").as(\"point\"))\n",
    "  .show()\n",
    "\n",
    "val duration1 = (System.nanoTime - t1) / 1e9d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b089a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration1 = 2.065082583\n"
     ]
    }
   ],
   "source": [
    "println(s\"duration1 = $duration1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70e16e",
   "metadata": {},
   "source": [
    "Вариант решения этой задачи без UDAF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+-------------+-----+\n",
      "|   firstName|lastName|state|sum(quantity)|point|\n",
      "+------------+--------+-----+-------------+-----+\n",
      "|Jean-Georges|  Perrin|   NC|            3|    3|\n",
      "|Jean-Georges|  Perrin|   CA|            4|    3|\n",
      "|      Holden|   Karau|   CA|           10|    6|\n",
      "|       Ginni| Rometty|   NY|            7|    3|\n",
      "+------------+--------+-----+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmax\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3\u001b[39m\n",
       "\u001b[36mt2\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m22911589203250L\u001b[39m\n",
       "\u001b[36mduration2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m3.464453083\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val max = pointAttribution.MAX_POINT_PER_ORDER\n",
    "\n",
    "val t2 = System.nanoTime\n",
    "data\n",
    "  .withColumn(\"point\", when($\"quantity\".$greater(max), max).otherwise($\"quantity\"))\n",
    "  .groupBy($\"firstName\", $\"lastName\", $\"state\")\n",
    "  .agg(sum(\"quantity\"), sum(\"point\").as(\"point\"))\n",
    "  .show()\n",
    "        \n",
    "val duration2 = (System.nanoTime - t2) / 1e9d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc68c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration1 = 2.065082583\n",
      "duration2 = 3.464453083\n",
      "duration1 - duration2 = -1.3993704999999999\n"
     ]
    }
   ],
   "source": [
    "println(s\"duration1 = $duration1\\nduration2 = $duration2\\nduration1 - duration2 = ${duration1 - duration2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d7443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
