{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f3eae9-38ea-40bf-bb2b-f3ba0eb393c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bb7f1-1649-4419-be8a-2cab7ba0b3f2",
   "metadata": {},
   "source": [
    "Создаём SparkSession. Добавляем путь к драйверу JDBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a24d33-f85f-4ba6-95ae-61901ddacac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/13 16:53:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"JDBC Data Source\")\n",
    "        .config(\"spark.jars\", \"jars/postgresql-42.7.2.jar\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.log.level\", \"WARN\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d0b6e-76bb-421c-920d-02cb84e72411",
   "metadata": {},
   "source": [
    "Задаём свойства подключения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d93afc-be0e-420d-af36-4247fdf8cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"org.postgresql.Driver\"\n",
    "url = \"jdbc:postgresql://localhost:5432/spark\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e48b3-e72b-48ce-90fd-5e66f3cc117c",
   "metadata": {},
   "source": [
    "## Чтение таблицы целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533923fc-54c6-4bdd-b324-32c6baf9dce9",
   "metadata": {},
   "source": [
    "### Вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713126df-fb47-451a-8c14-36afe87ae5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees\") \\\n",
    "    .load()\n",
    "\n",
    "employees_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6390bf25-1579-47dc-a8d5-0f6982660057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_no: integer (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2108bedf-5ec3-4ff7-9706-d48c293e8eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "| 10030|1958-07-14|     Elvis|    Demeyer|     M|1994-02-17|\n",
      "| 10040|1959-09-13|     Weiyi|    Meriste|     F|1993-02-14|\n",
      "| 10050|1958-05-21|   Yinghua|     Dredge|     M|1990-12-25|\n",
      "| 10060|1961-10-15|  Breannda|Billingsley|     M|1987-11-02|\n",
      "| 10070|1955-08-20|    Reuven| Garigliano|     M|1985-10-14|\n",
      "| 10080|1957-12-03|    Premal|       Baek|     M|1985-11-19|\n",
      "| 10090|1961-05-30|    Kendra|    Hofting|     M|1986-03-14|\n",
      "| 10100|1953-04-21|  Hironobu|  Haraldson|     F|1987-09-21|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc472-968d-4e5f-aa08-d0593bc9b877",
   "metadata": {},
   "source": [
    "### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d45f91-da3b-488f-9021-4fd4ae5831dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBPARAMS = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": driver\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b03b075-33a3-4358-99b5-fa0f40103aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1ca1ac-5e58-4c85-989e-45cd14e6d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_no: integer (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876be6b8-58b1-4d63-8790-d980253351ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "| 10030|1958-07-14|     Elvis|    Demeyer|     M|1994-02-17|\n",
      "| 10040|1959-09-13|     Weiyi|    Meriste|     F|1993-02-14|\n",
      "| 10050|1958-05-21|   Yinghua|     Dredge|     M|1990-12-25|\n",
      "| 10060|1961-10-15|  Breannda|Billingsley|     M|1987-11-02|\n",
      "| 10070|1955-08-20|    Reuven| Garigliano|     M|1985-10-14|\n",
      "| 10080|1957-12-03|    Premal|       Baek|     M|1985-11-19|\n",
      "| 10090|1961-05-30|    Kendra|    Hofting|     M|1986-03-14|\n",
      "| 10100|1953-04-21|  Hironobu|  Haraldson|     F|1987-09-21|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c21403-9cfb-4c5f-a3be-fde85d3d7f87",
   "metadata": {},
   "source": [
    "Проверим количество партиций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0645e84-b0a1-4570-a6b2-dfbcef91667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88633689-14d4-4dac-9693-936a1ee13db0",
   "metadata": {},
   "source": [
    "## Как распараллелить чтение?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a05e8-9844-4e11-817e-cea50cece673",
   "metadata": {},
   "source": [
    "### Партиционирование по столбцам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabc184-42ed-4ebb-960f-daf600d91d37",
   "metadata": {},
   "source": [
    "Добавим количество партиций к параметрам чтения таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977f86f6-08e8-4b6d-8464-216814fa6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  30003\n",
      "num partitions =  1\n"
     ]
    }
   ],
   "source": [
    "df101 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, numPartitions=10)\n",
    "\n",
    "print(\"count = \", df101.count())\n",
    "print(\"num partitions = \", df101.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f57bc1-dd8a-40f1-af8d-f49c6c6e0c94",
   "metadata": {},
   "source": [
    "Количество партиций не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80da1c8-5d28-44ba-a3dd-68aec3a7a4d9",
   "metadata": {},
   "source": [
    "Узнаем минимальное и максимальное значения столбца *emp_no*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2b053c-f203-4a84-8639-8a9857cab891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|min(emp_no)|max(emp_no)|\n",
      "+-----------+-----------+\n",
      "|      10010|     499990|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(min(col(\"emp_no\")), max(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0181e231-5e06-42e2-b960-286c99b84514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min =  10010 \n",
      "max =  499990\n"
     ]
    }
   ],
   "source": [
    "min_emp_no = df.agg(min(col(\"emp_no\"))).collect()[0][0]\n",
    "max_emp_no = df.agg(max(col(\"emp_no\"))).collect()[0][0]\n",
    "\n",
    "print(\"min = \", min_emp_no, \"\\nmax = \", max_emp_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af774fc1-af16-4b3c-bbe1-caba23ed49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  30003\n",
      "num partitions =  10\n"
     ]
    }
   ],
   "source": [
    "df102 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS,\n",
    "                        column=\"emp_no\", lowerBound = min_emp_no, upperBound = max_emp_no, numPartitions=10)\n",
    "\n",
    "print(\"count = \", df102.count())\n",
    "print(\"num partitions = \", df102.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2984c9db-4dce-4266-9feb-b874960c62c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "| 10030|1958-07-14|     Elvis|    Demeyer|     M|1994-02-17|\n",
      "| 10040|1959-09-13|     Weiyi|    Meriste|     F|1993-02-14|\n",
      "| 10050|1958-05-21|   Yinghua|     Dredge|     M|1990-12-25|\n",
      "| 10060|1961-10-15|  Breannda|Billingsley|     M|1987-11-02|\n",
      "| 10070|1955-08-20|    Reuven| Garigliano|     M|1985-10-14|\n",
      "| 10080|1957-12-03|    Premal|       Baek|     M|1985-11-19|\n",
      "| 10090|1961-05-30|    Kendra|    Hofting|     M|1986-03-14|\n",
      "| 10100|1953-04-21|  Hironobu|  Haraldson|     F|1987-09-21|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df102.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa7a71-d146-4493-8ff7-43a335500c2a",
   "metadata": {},
   "source": [
    "Посмотрим сколько записей попало в каждую партицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ed3b02-4fd1-41c1-b9b0-89b44decd378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partition count =  4900                                            (0 + 1) / 10]\n",
      "Partition count =  4900                                            (1 + 1) / 10]\n",
      "Partition count =  203\n",
      "Partition count =  601\n",
      "Partition count =  4899\n",
      "Partition count =  4500===============>                            (5 + 1) / 10]\n",
      "Partition count =  0\n",
      "Partition count =  200\n",
      "Partition count =  4900\n",
      "Partition count =  4900======================================>     (9 + 1) / 10]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df102.rdd.foreachPartition(lambda p: print(\"Partition count = \", len(list(p))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5bee1-123c-417d-9ab5-1f937c0772d6",
   "metadata": {},
   "source": [
    "Это также можно получить другим способом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2463b5ea-729c-41ae-ac0e-295808a57d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 4900),\n",
       " (1, 4900),\n",
       " (2, 203),\n",
       " (3, 601),\n",
       " (4, 4899),\n",
       " (5, 4500),\n",
       " (6, 0),\n",
       " (7, 200),\n",
       " (8, 4900),\n",
       " (9, 4900)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = df102.rdd.mapPartitionsWithIndex(lambda p, i: (p, len(list(i)))).collect()\n",
    "list(zip(pl[::2], pl[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbd85b-1cc4-4a89-bbeb-71538e7907a5",
   "metadata": {},
   "source": [
    "Зададим в качестве *lowerBound* и *upperBound* произвольные значения (не min и max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a259f552-c19d-4f1d-a5de-1f16ff7dbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  30003\n",
      "num partitions =  10\n"
     ]
    }
   ],
   "source": [
    "df103 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees\") \\\n",
    "    .option(\"partitionColumn\", \"emp_no\") \\\n",
    "    .option(\"lowerBound\", \"20000\") \\\n",
    "    .option(\"upperBound\", \"50000\") \\\n",
    "    .option(\"numPartitions\", \"10\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"count = \", df103.count())\n",
    "print(\"num partitions = \", df103.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba4673-609d-4992-9315-92e00f32608b",
   "metadata": {},
   "source": [
    "Посмотрим сколько теперь записей попало в каждую партицию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6a4bd7b-2e72-45ff-9e87-ebd934e585ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1299),\n",
       " (1, 300),\n",
       " (2, 300),\n",
       " (3, 300),\n",
       " (4, 300),\n",
       " (5, 300),\n",
       " (6, 300),\n",
       " (7, 300),\n",
       " (8, 300),\n",
       " (9, 26304)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl2 = df103.rdd.mapPartitionsWithIndex(lambda p, i: (p, len(list(i)))).collect()\n",
    "list(zip(pl2[::2], pl2[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "136125f9-c347-4dae-a943-fb2b7f07b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "| 10030|1958-07-14|     Elvis|    Demeyer|     M|1994-02-17|\n",
      "| 10040|1959-09-13|     Weiyi|    Meriste|     F|1993-02-14|\n",
      "| 10050|1958-05-21|   Yinghua|     Dredge|     M|1990-12-25|\n",
      "| 10060|1961-10-15|  Breannda|Billingsley|     M|1987-11-02|\n",
      "| 10070|1955-08-20|    Reuven| Garigliano|     M|1985-10-14|\n",
      "| 10080|1957-12-03|    Premal|       Baek|     M|1985-11-19|\n",
      "| 10090|1961-05-30|    Kendra|    Hofting|     M|1986-03-14|\n",
      "| 10100|1953-04-21|  Hironobu|  Haraldson|     F|1987-09-21|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df103.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589186e0-7610-4cd0-9616-d417f4373dd1",
   "metadata": {},
   "source": [
    "### Партиционирование по предикатам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1c337-deee-4174-992d-ba289fb6af8a",
   "metadata": {},
   "source": [
    "### Пример 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f807e-d7e8-4bb9-9078-86e097871e8b",
   "metadata": {},
   "source": [
    "Опредилим **два** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61c972b0-a975-4a83-b36f-7ad0fb79270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  30003\n",
      "num partitions =  2\n"
     ]
    }
   ],
   "source": [
    "pred = [\"gender = 'M'\", \"gender = 'F'\"]\n",
    "\n",
    "df_pred = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred)\n",
    "\n",
    "print(\"count = \", df_pred.count())\n",
    "print(\"num partitions = \", df_pred.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da8606-665e-49aa-bbe7-941ae4bae4c4",
   "metadata": {},
   "source": [
    "Опредилим **один** предиката по одному значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77855569-49cd-41eb-8e74-26e763d138e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  12091\n",
      "num partitions =  1\n"
     ]
    }
   ],
   "source": [
    "pred1 = [\"gender = 'F'\"]\n",
    "\n",
    "df_pred1 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred1)\n",
    "\n",
    "print(\"count = \", df_pred1.count())\n",
    "print(\"num partitions = \", df_pred1.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e15ad-f9e9-496f-954a-6fe695d34305",
   "metadata": {},
   "source": [
    "Опредилим **три** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a9fb889-6910-4f21-a1c5-7e8f5ec0d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  47915\n",
      "num partitions =  3\n"
     ]
    }
   ],
   "source": [
    "pred3 = [\"gender = 'F'\", \"gender = 'M'\", \"gender = 'M'\"]\n",
    "\n",
    "df_pred3 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred3)\n",
    "\n",
    "print(\"count = \", df_pred3.count())\n",
    "print(\"num partitions = \", df_pred3.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f6bec-3e12-4c84-92c9-ae944d283f7d",
   "metadata": {},
   "source": [
    "Опредилим **четыре** предиката по значению столбца *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e31949-df44-43fc-85f7-d03e791df04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  60006\n",
      "num partitions =  4\n"
     ]
    }
   ],
   "source": [
    "pred4 = [\"gender = 'F'\", \"gender = 'F'\", \"gender = 'M'\", \"gender = 'M'\"]\n",
    "\n",
    "df_pred4 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred4)\n",
    "\n",
    "print(\"count = \", df_pred4.count())\n",
    "print(\"num partitions = \", df_pred4.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2d3b9-ed24-4d7b-af6a-542b02010aab",
   "metadata": {},
   "source": [
    "Посмотрим сколько записей для каждого значения столбца *gender* было в исходной таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ed3d76-26e2-4c56-8231-4bfd850004d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|gender|count(emp_no)|\n",
      "+------+-------------+\n",
      "|     F|        12091|\n",
      "|     M|        17912|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282af4c-dbdf-4d1d-98b9-bbd4e6fdeb3f",
   "metadata": {},
   "source": [
    "Сравним с количеством записей при применении трёх и четырёх предикатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23f5c54c-63c4-46c5-9501-8524f6b5455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|gender|count(emp_no)|\n",
      "+------+-------------+\n",
      "|     F|        12091|\n",
      "|     M|        35824|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred3.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f63b5f80-243a-4396-a907-0bfe3a57162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|gender|count(emp_no)|\n",
      "+------+-------------+\n",
      "|     F|        24182|\n",
      "|     M|        35824|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred4.groupBy(col(\"gender\")).agg(count(col(\"emp_no\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc51989-2137-4aa0-bdc6-2ef9e7673147",
   "metadata": {},
   "source": [
    "### Пример 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596b34-83d3-4a27-a75a-24f04e83957c",
   "metadata": {},
   "source": [
    "Определим **два** предиката по условиям на значения столбца *emp_no* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16f107cc-d5ca-47ea-8531-74192817c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  8001\n",
      "num partitions =  2\n"
     ]
    }
   ],
   "source": [
    "pred2 = [\"emp_no > 20000 and emp_no <= 50000\", \"emp_no >= 50000 and emp_no <= 100000\"]\n",
    "\n",
    "df_pred2 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred2)\n",
    "\n",
    "print(\"count = \", df_pred2.count())\n",
    "print(\"num partitions = \", df_pred2.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b73bd83-dd96-4f59-94d6-f0b93a2940ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 20010|1961-01-26|    Saniya|     Veccia|     M|1997-06-16|\n",
      "| 20020|1962-07-22|     Akeel|     Covnot|     F|1996-03-02|\n",
      "| 20030|1962-05-09|    Nitsan|Hoppenstand|     F|1988-11-18|\n",
      "| 20040|1962-04-16|   Youjian|    Vingron|     M|1987-01-21|\n",
      "| 20050|1959-02-27|  Guoxiang|   Greibach|     F|1991-03-18|\n",
      "| 20060|1954-07-18|    Chrisa|Attimonelli|     F|1985-10-16|\n",
      "| 20070|1959-04-13|       Tse|    Bellone|     M|1992-07-08|\n",
      "| 20080|1962-03-22|   Odoardo|  Heiserman|     F|1991-07-01|\n",
      "| 20090|1957-05-20| Serenella|   Kaltofen|     F|1986-06-24|\n",
      "| 20100|1965-01-18|       Utz|     Heuter|     F|1986-06-15|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e22f41-98d3-4974-9999-66dc33cb343e",
   "metadata": {},
   "source": [
    "Определим **один** предикат по условию на значения столбца *emp_no* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f604e53-ce36-46eb-94fd-87e8bae0a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  3000\n",
      "num partitions =  1\n"
     ]
    }
   ],
   "source": [
    "pred22 = [\"emp_no > 20000 and emp_no <= 50000\"]\n",
    "\n",
    "df_pred22 = spark.read.jdbc(url=url, table=\"public.employees\", properties=DBPARAMS, predicates=pred22)\n",
    "\n",
    "print(\"count = \", df_pred22.count())\n",
    "print(\"num partitions = \", df_pred22.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cbc17-1126-426c-8c2c-bce7b04457cd",
   "metadata": {},
   "source": [
    "## Фильтрация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9167cd-ef11-4203-a739-0538aa42efa6",
   "metadata": {},
   "source": [
    "Выполним запрос к базе на выборку значений из таблицы с условием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "578941e3-3219-451e-9a3b-4f545b12af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"select * from public.employees where emp_no > 20000 and emp_no <= 50000\"\"\"\n",
    "\n",
    "dfq = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"query\", q) \\\n",
    "    .load()\n",
    "\n",
    "dfq.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be8a7dac-86bc-4730-aafe-a583b31be665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 20010|1961-01-26|    Saniya|     Veccia|     M|1997-06-16|\n",
      "| 20020|1962-07-22|     Akeel|     Covnot|     F|1996-03-02|\n",
      "| 20030|1962-05-09|    Nitsan|Hoppenstand|     F|1988-11-18|\n",
      "| 20040|1962-04-16|   Youjian|    Vingron|     M|1987-01-21|\n",
      "| 20050|1959-02-27|  Guoxiang|   Greibach|     F|1991-03-18|\n",
      "| 20060|1954-07-18|    Chrisa|Attimonelli|     F|1985-10-16|\n",
      "| 20070|1959-04-13|       Tse|    Bellone|     M|1992-07-08|\n",
      "| 20080|1962-03-22|   Odoardo|  Heiserman|     F|1991-07-01|\n",
      "| 20090|1957-05-20| Serenella|   Kaltofen|     F|1986-06-24|\n",
      "| 20100|1965-01-18|       Utz|     Heuter|     F|1986-06-15|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfq.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984111f-0675-46ed-a91c-addf3be33a66",
   "metadata": {},
   "source": [
    "## Соединения в базе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accb0b4-b895-4f85-b0ba-54dc569ea936",
   "metadata": {},
   "source": [
    "Выполним запрос к базе на выборку значений из соединения таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78d29ff9-b3db-44da-a10e-20ce751d83a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qj = \"\"\"select e.emp_no, birth_date, first_name, last_name, gender, hire_date, salary, from_date, to_date\n",
    "from employees e join salaries s on e.emp_no = s.emp_no\"\"\"\n",
    "\n",
    "dfj = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"query\", qj) \\\n",
    "    .load()\n",
    "\n",
    "dfj.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05627caa-afc5-447b-a747-bbe6472cd271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+------+----------+----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|salary| from_date|   to_date|\n",
      "+------+----------+----------+---------+------+----------+------+----------+----------+\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 72488|1996-11-24|1997-11-24|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 74347|1997-11-24|1998-11-24|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 75405|1998-11-24|1999-11-24|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 78194|1999-11-24|2000-11-23|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 79580|2000-11-23|2001-11-23|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24| 80324|2001-11-23|9999-01-01|\n",
      "| 10020|1952-12-24|    Mayuko|  Warwick|     M|1991-01-26| 40000|1997-12-30|1998-12-30|\n",
      "| 10020|1952-12-24|    Mayuko|  Warwick|     M|1991-01-26| 40647|1998-12-30|1999-12-30|\n",
      "| 10020|1952-12-24|    Mayuko|  Warwick|     M|1991-01-26| 43800|1999-12-30|2000-12-29|\n",
      "| 10020|1952-12-24|    Mayuko|  Warwick|     M|1991-01-26| 44927|2000-12-29|2001-12-29|\n",
      "| 10020|1952-12-24|    Mayuko|  Warwick|     M|1991-01-26| 47017|2001-12-29|9999-01-01|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 66956|1994-02-17|1995-02-17|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 68393|1995-02-17|1996-02-17|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 72795|1996-02-17|1997-02-16|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 76453|1997-02-16|1998-02-16|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 79290|1998-02-16|1999-02-16|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 83327|1999-02-16|2000-02-16|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 86634|2000-02-16|2001-02-15|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 87027|2001-02-15|2002-02-15|\n",
      "| 10030|1958-07-14|     Elvis|  Demeyer|     M|1994-02-17| 88806|2002-02-15|9999-01-01|\n",
      "+------+----------+----------+---------+------+----------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfj.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865d95a-04a8-43a8-8f35-8562f0c6ef00",
   "metadata": {},
   "source": [
    "## Запись в таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1e6bb-0c80-425e-808b-7c70899dd1e3",
   "metadata": {},
   "source": [
    "Посмотрим на таблицу *employees*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce5d1c16-07de-4e6b-af94-89dec58f8725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "| 10030|1958-07-14|     Elvis|    Demeyer|     M|1994-02-17|\n",
      "| 10040|1959-09-13|     Weiyi|    Meriste|     F|1993-02-14|\n",
      "| 10050|1958-05-21|   Yinghua|     Dredge|     M|1990-12-25|\n",
      "| 10060|1961-10-15|  Breannda|Billingsley|     M|1987-11-02|\n",
      "| 10070|1955-08-20|    Reuven| Garigliano|     M|1985-10-14|\n",
      "| 10080|1957-12-03|    Premal|       Baek|     M|1985-11-19|\n",
      "| 10090|1961-05-30|    Kendra|    Hofting|     M|1986-03-14|\n",
      "| 10100|1953-04-21|  Hironobu|  Haraldson|     F|1987-09-21|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d9fb8-d69b-4c1b-854f-ff2f34ea59ff",
   "metadata": {},
   "source": [
    "Загрузим таблицу *salaries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a52af57a-4b5d-4b3c-a82c-bce22c3a0ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283827"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.salaries\") \\\n",
    "    .load()\n",
    "\n",
    "salaries_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8165df63-e102-449f-878e-8ca17b70cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+----------+\n",
      "|emp_no|salary| from_date|   to_date|\n",
      "+------+------+----------+----------+\n",
      "| 10010| 72488|1996-11-24|1997-11-24|\n",
      "| 10010| 74347|1997-11-24|1998-11-24|\n",
      "| 10010| 75405|1998-11-24|1999-11-24|\n",
      "| 10010| 78194|1999-11-24|2000-11-23|\n",
      "| 10010| 79580|2000-11-23|2001-11-23|\n",
      "| 10010| 80324|2001-11-23|9999-01-01|\n",
      "| 10020| 40000|1997-12-30|1998-12-30|\n",
      "| 10020| 40647|1998-12-30|1999-12-30|\n",
      "| 10020| 43800|1999-12-30|2000-12-29|\n",
      "| 10020| 44927|2000-12-29|2001-12-29|\n",
      "+------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salaries_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af1db4-cb4c-4b2b-bf7a-bab606db3ae8",
   "metadata": {},
   "source": [
    "Сделаем группировку по колонке *emp_no* и найдём максимальное значение колонки *salary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b62ace4d-6ce6-471a-8d6d-e71784fff159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|emp_no|max_salary|\n",
      "+------+----------+\n",
      "| 12940|     85425|\n",
      "| 13840|     41453|\n",
      "| 14450|     75524|\n",
      "| 14570|     72506|\n",
      "| 15790|     79009|\n",
      "| 17420|     97003|\n",
      "| 18800|     88342|\n",
      "| 19530|     47864|\n",
      "| 21220|     86177|\n",
      "| 21700|     68115|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_salaries_df = salaries_df.groupBy(col(\"emp_no\")).agg(max(col(\"salary\")).alias(\"max_salary\"))\n",
    "\n",
    "employees_salaries_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad45c36-b390-450c-b890-7436af2b4f53",
   "metadata": {},
   "source": [
    "Создадим новый Dataframe как результат соединения *employees_df* и агрегированного *salaries_df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41c68c73-9ad1-4b6c-a001-3e223d9764b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|max_salary|\n",
      "+------+----------+----------+---------+------+----------+----------+\n",
      "| 12940|1953-10-25|  Odinaldo|   Farrar|     F|1987-12-12|     85425|\n",
      "| 13840|1954-11-13|     Remco|    Demke|     M|1992-06-09|     41453|\n",
      "| 14450|1963-08-01|  Fumitaka|Prochazka|     F|1985-04-26|     75524|\n",
      "| 14570|1963-07-26|    Chinho|     Bala|     F|1994-11-17|     72506|\n",
      "| 15790|1960-03-20|     Kokou| Schnabel|     M|1991-04-03|     79009|\n",
      "| 17420|1964-05-22|     Jinpo|Stamatiou|     F|1987-07-31|     97003|\n",
      "| 18800|1962-05-21|    Baruch|  Rosiles|     F|1990-07-06|     88342|\n",
      "| 19530|1953-12-26|     Barry|   Dratva|     M|1997-09-02|     47864|\n",
      "| 21220|1956-05-11|      Mana|  Murtagh|     M|1991-10-29|     86177|\n",
      "| 21700|1963-07-12|       Urs|  Plesums|     F|1992-03-07|     68115|\n",
      "| 27760|1959-12-05|    Zhigen|  Schrift|     M|1991-04-03|     63106|\n",
      "| 28170|1964-05-19|     Jiong|  Bamford|     M|1997-05-03|     56862|\n",
      "| 30970|1956-02-16|  Fumitake| Schoegge|     F|1986-12-01|     69833|\n",
      "| 32460|1957-10-08|   Kousuke|    Rotem|     M|1987-10-17|     73387|\n",
      "| 35820|1953-02-26|  Michaela|   Brizzi|     F|1990-07-22|     87087|\n",
      "| 38220|1952-07-05|      Maya|   Terkki|     M|1986-08-31|     79664|\n",
      "| 41890|1958-05-19|      Kirk|   Pettit|     M|1995-12-02|     58692|\n",
      "| 48510|1959-09-12|      Shih| Savasere|     F|1987-11-20|     59676|\n",
      "| 54190|1960-08-01|    Doowon|   Ashish|     F|1990-12-24|     72968|\n",
      "| 56110|1953-06-13|     Jouni|   Reeken|     F|1988-08-16|     47841|\n",
      "+------+----------+----------+---------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_salaries_df = employees_df.join(employees_salaries_df, \"emp_no\")\n",
    "\n",
    "employees_salaries_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca3454-0902-4063-9ff2-a130906a5e1b",
   "metadata": {},
   "source": [
    "Сохраним новый Dataframe в таблицу в базе. Таблицы с таким именем в базе не было. Она будет создана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb8e03d5-7f0c-420f-b743-437c27145a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a6b6c-153a-448d-a65d-cff200cc3e01",
   "metadata": {},
   "source": [
    "Если таблица с таким именем существовала в базе, то при сохранении надо использовать режим *overwrite*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94655e73-5684-439d-94c5-37c7e688a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .option(\"truncate\", \"true\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6a4340a-65bf-4e3b-99d1-b9f94f97edd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30003"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .load() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c39cda-6e7e-4ecc-8167-8ea03069c5ee",
   "metadata": {},
   "source": [
    "Если использовать режим *append* содержимое Dataframe будет добавлено в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8def5b68-c6b9-433b-8411-c298430de648",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_salaries_df.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a14d493c-9d24-4814-80ca-4a955e4b4fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60006"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", driver) \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"dbtable\", \"public.employees_salaries\") \\\n",
    "    .load() \\\n",
    "    .count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
